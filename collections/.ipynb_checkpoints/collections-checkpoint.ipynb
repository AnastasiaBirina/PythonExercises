{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05cdba15-6d2e-44c4-844b-969971a2e51a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff4112-0025-449d-bb30-45dce3506fbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2267eb-8810-4dbb-a44b-f06eb0174971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "csv_data = [['nylon', '10', 'unimportant'], ['leather', '4', 'unimportant'], ['wool', '1', 'important'], ['leather', '1', 'unimportant'], ['nylon', '1', 'unimportant'], ['polyester', '2', 'important'], ['silk', '1', 'important'], ['cotton', '5', 'important'], ['cotton', '5', 'important'], ['leather', '3', 'unimportant'], ['silk thread', '5', 'important'], ['nylon', '6', 'unimportant'], ['cotton', '3', 'unimportant'], ['leather', '8', 'unimportant'], ['polyester', '2', 'unimportant'], ['cotton thread', '5', 'important'], ['denim', '8', 'important'], ['cotton thread', '10', 'unimportant'], ['silk thread', '9', 'important'], ['cotton', '5', 'important'], ['elastic thread', '7', 'unimportant'], ['polyester thread', '7', 'important'], ['polyester', '7', 'important'], ['polyester thread', '9', 'important'], ['polyester', '6', 'unimportant'], ['denim thread', '8', 'unimportant'], ['silk', '2', 'important'], ['nylon', '6', 'unimportant'], ['elastic thread', '1', 'unimportant'], ['elastic thread', '9', 'important'], ['linen thread', '7', 'unimportant'], ['cotton', '4', 'unimportant'], ['elastic thread', '6', 'important'], ['nylon', '8', 'unimportant'], ['silk', '5', 'unimportant'], ['polyester thread', '6', 'unimportant'], ['denim thread', '6', 'important'], ['denim', '2', 'important'], ['polyester', '10', 'important'], ['polyester', '9', 'unimportant'], ['polyester thread', '8', 'unimportant'], ['silk', '5', 'unimportant'], ['wool', '4', 'important'], ['linen thread', '7', 'important'], ['linen thread', '4', 'unimportant'], ['cotton thread', '7', 'unimportant'], ['elastic thread', '2', 'unimportant'], ['wool', '3', 'important'], ['silk thread', '4', 'unimportant'], ['silk', '3', 'important'], ['nylon', '10', 'important'], ['leather', '7', 'important'], ['denim', '9', 'important'], ['nylon', '3', 'important'], ['denim', '8', 'important'], ['linen thread', '5', 'important'], ['polyester', '4', 'important'], ['silk thread', '9', 'unimportant'], ['elastic thread', '3', 'unimportant'], ['leather', '10', 'important'], ['elastic thread', '6', 'unimportant'], ['silk', '10', 'unimportant'], ['cotton', '6', 'unimportant'], ['linen thread', '4', 'important'], ['nylon', '1', 'unimportant'], ['denim thread', '4', 'important'], ['polyester thread', '9', 'important'], ['leather', '9', 'unimportant'], ['polyester thread', '5', 'unimportant'], ['denim thread', '5', 'important'], ['wool', '7', 'important'], ['linen thread', '3', 'important'], ['linen thread', '10', 'important'], ['polyester', '6', 'important'], ['silk thread', '2', 'unimportant'], ['leather', '3', 'important'], ['cotton', '9', 'unimportant'], ['wool', '6', 'important'], ['denim', '2', 'important'], ['elastic thread', '2', 'unimportant'], ['nylon', '5', 'important'], ['polyester', '8', 'unimportant'], ['polyester', '5', 'unimportant'], ['polyester', '10', 'important'], ['leather', '4', 'unimportant'], ['elastic thread', '7', 'unimportant'], ['wool', '4', 'unimportant'], ['cotton', '5', 'unimportant'], ['leather', '7', 'unimportant'], ['leather', '4', 'unimportant'], ['linen thread', '4', 'important'], ['polyester', '2', 'important'], ['wool', '6', 'important'], ['polyester', '8', 'unimportant'], ['linen thread', '9', 'unimportant'], ['elastic thread', '8', 'unimportant'], ['denim', '9', 'important'], ['silk thread', '5', 'important'], ['silk', '1', 'unimportant'], ['silk', '6', 'unimportant']]\n",
    "\n",
    "supplies_deque = deque()\n",
    "for data in csv_data:\n",
    "    if data[2] == 'important':\n",
    "        supplies_deque.appendleft(data)\n",
    "    else:\n",
    "        supplies_deque.append(data)\n",
    "\n",
    "ordered_important_supplies = deque()\n",
    "ordered_unimportant_supplies = deque()\n",
    "\n",
    "for i in range(25):\n",
    "    ordered_important_supplies.append(supplies_deque.popleft())\n",
    "\n",
    "for i in range(10):\n",
    "    ordered_unimportant_supplies.append(supplies_deque.pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f2656-7051-479c-b854-b8b1e0f2fc11",
   "metadata": {},
   "source": [
    "#### Named Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0facca8f-077a-4728-8d99-a8c6c735465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ClothingItem(type='t-shirt', color='green', size='large', price=9.99), ClothingItem(type='jeans', color='blue', size='medium', price=14.99), ClothingItem(type='jacket', color='black', size='x-large', price=19.99), ClothingItem(type='t-shirt', color='grey', size='small', price=8.99), ClothingItem(type='shoes', color='white', size='12', price=24.99), ClothingItem(type='t-shirt', color='grey', size='small', price=8.99)]\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "clothes = [('t-shirt', 'green', 'large', 9.99),\n",
    "           ('jeans', 'blue', 'medium', 14.99),\n",
    "           ('jacket', 'black', 'x-large', 19.99),\n",
    "           ('t-shirt', 'grey', 'small', 8.99),\n",
    "           ('shoes', 'white', '12', 24.99),\n",
    "           ('t-shirt', 'grey', 'small', 8.99)]\n",
    "\n",
    "ClothingItem = namedtuple('ClothingItem', ['type', 'color', 'size', 'price'])\n",
    "new_coat = ClothingItem('coat', 'black', 'small', 14.99)\n",
    "coat_cost = new_coat.price\n",
    "\n",
    "updated_clothes_data = []\n",
    "for i in clothes:\n",
    "    updated_clothes_data.append(ClothingItem(i[0], i[1], i[2], i[3]))\n",
    "\n",
    "print(updated_clothes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab00bc-b08e-4e2a-aa38-88121522dbad",
   "metadata": {},
   "source": [
    "#### DefaultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92146309-f6f8-4d23-8594-9cc8bd21608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x00000200D24CA550>, {'t-shirt': 'Shirts', 'dress shirt': 'Shirts', 'flannel shirt': 'Shirts', 'sweatshirt': 'Shirts', 'jeans': 'Pants', 'dress pants': 'Pants', 'cropped pants': 'Pants', 'leggings': 'Pants'})\n",
      "\n",
      "{'t-shirt': 'Shirts', 'dress shirt': 'Shirts', 'flannel shirt': 'Shirts', 'sweatshirt': 'Shirts', 'jeans': 'Pants', 'dress pants': 'Pants', 'cropped pants': 'Pants', 'leggings': 'Pants', 'draped blouse': 'TODO: Add to website', 'undershirt': 'TODO: Add to website', 'sun dress': 'TODO: Add to website', 'camisole top': 'TODO: Add to website'}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "site_locations = {'t-shirt': 'Shirts',\n",
    "                  'dress shirt': 'Shirts',\n",
    "                  'flannel shirt': 'Shirts',\n",
    "                  'sweatshirt': 'Shirts',\n",
    "                  'jeans': 'Pants',\n",
    "                  'dress pants': 'Pants',\n",
    "                  'cropped pants': 'Pants',\n",
    "                  'leggings': 'Pants'\n",
    "                  }\n",
    "updated_products = ['draped blouse', 'leggings', 'undershirt', 'dress shirt', 'jeans', 'sun dress', 'flannel shirt', 'cropped pants', 'dress pants', 't-shirt', 'camisole top', 'sweatshirt']\n",
    "\n",
    "validated_locations = defaultdict(lambda: 'TODO: Add to website')\n",
    "validated_locations.update(site_locations)\n",
    "print(validated_locations)\n",
    "\n",
    "for i in updated_products:\n",
    "    site_locations[i] = validated_locations[i]\n",
    "print()\n",
    "print(site_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437da1c-624b-4593-aaca-28107fecd600",
   "metadata": {},
   "source": [
    "#### OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e46444-07ab-4306-abc9-8cb91ca1d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Order: 1', 'purchased'), ('Order: 2', 'purchased'), ('Order: 3', 'purchased'), ('Order: 5', 'purchased'), ('Order: 8', 'purchased'), ('Order: 11', 'purchased'), ('Order: 13', 'purchased'), ('Order: 15', 'purchased'), ('Order: 4', 'returned'), ('Order: 7', 'returned'), ('Order: 9', 'returned'), ('Order: 12', 'returned')])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# The first 15 orders are provided\n",
    "order_data = [['Order: 1', 'purchased'],\n",
    "              ['Order: 2', 'purchased'],\n",
    "              ['Order: 3', 'purchased'],\n",
    "              ['Order: 4', 'returned'],\n",
    "              ['Order: 5', 'purchased'],\n",
    "              ['Order: 6', 'canceled'],\n",
    "              ['Order: 7', 'returned'],\n",
    "              ['Order: 8', 'purchased'],\n",
    "              ['Order: 9', 'returned'],\n",
    "              ['Order: 10', 'canceled'],\n",
    "              ['Order: 11', 'purchased'],\n",
    "              ['Order: 12', 'returned'],\n",
    "              ['Order: 13', 'purchased'],\n",
    "              ['Order: 14', 'canceled'],\n",
    "              ['Order: 15', 'purchased']]\n",
    "\n",
    "orders = OrderedDict(order_data)\n",
    "\n",
    "to_move = []\n",
    "to_remove = []\n",
    "\n",
    "for i in order_data:\n",
    "    if i[1] == 'canceled':\n",
    "        to_remove.append(i[0])\n",
    "    elif i[1] == 'returned':\n",
    "        to_move.append(i[0])  \n",
    "\n",
    "for i in to_remove:\n",
    "      orders.pop(i)\n",
    "\n",
    "for i in to_move:\n",
    "    orders.move_to_end(i)\n",
    "\n",
    "print(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c41626-ecd2-471f-b693-e034e6929379",
   "metadata": {},
   "source": [
    "#### ChainMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5020f58-17e1-41f9-9c03-0ca487f2d2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard:  3834.8700000000244\n",
      "holiday:  3427.09\n"
     ]
    }
   ],
   "source": [
    "from collections import ChainMap\n",
    "year_profit_data = [\n",
    "    {'jan_profit': 15492.30, 'jan_holiday_profit': 2589.12},\n",
    "    {'feb_profit': 17018.05, 'feb_holiday_profit': 3701.88},\n",
    "    {'mar_profit': 11849.13},\n",
    "    {'apr_profit': 9870.68},\n",
    "    {'may_profit': 13662.34},\n",
    "    {'jun_profit': 12903.54},\n",
    "    {'jul_profit': 16965.08, 'jul_holiday_profit': 4360.21},\n",
    "    {'aug_profit': 17685.69},\n",
    "    {'sep_profit': 9815.57},\n",
    "    {'oct_profit': 10318.28},\n",
    "    {'nov_profit': 23295.43, 'nov_holiday_profit': 9896.55},\n",
    "    {'dec_profit': 21920.19, 'dec_holiday_profit': 8060.79}\n",
    "]\n",
    "\n",
    "new_months_data = [\n",
    "    {'jan_profit': 13977.85, 'jan_holiday_profit': 2176.43},\n",
    "    {'feb_profit': 16692.15, 'feb_holiday_profit': 3239.74},\n",
    "    {'mar_profit': 17524.35, 'mar_holiday_profit': 4301.92}\n",
    "]\n",
    "\n",
    "profit_map = ChainMap(*year_profit_data)\n",
    "\n",
    "def get_profits(chain_dict):\n",
    "    last_year_standard_profit  = 0.00\n",
    "    last_year_holiday_profit = 0.00\n",
    "    for key in chain_dict.keys():\n",
    "        if 'holiday' in key:  \n",
    "            last_year_holiday_profit += chain_dict[key]\n",
    "        else:  \n",
    "            last_year_standard_profit  += chain_dict[key]\n",
    "    return last_year_standard_profit, last_year_holiday_profit \n",
    "\n",
    "last_year_standard_profit, last_year_holiday_profit = get_profits(profit_map)\n",
    "\n",
    "for item in new_months_data:\n",
    "    profit_map = profit_map.new_child(item)\n",
    "    \n",
    "current_year_standard_profit, current_year_holiday_profit = get_profits(profit_map)\n",
    "\n",
    "year_diff_standard_profit = current_year_standard_profit - last_year_standard_profit\n",
    "year_diff_holiday_profit = current_year_holiday_profit - last_year_holiday_profit\n",
    "\n",
    "print('standard: ', year_diff_standard_profit)\n",
    "print('holiday: ', year_diff_holiday_profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9404f7-9c19-4aef-8ec3-6919aa7d5977",
   "metadata": {},
   "source": [
    "#### Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf633c40-15f7-40a2-8cd5-32db0927bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "opening_inventory = ['shoes', 'shoes', 'skirt', 'jeans', 'blouse', 'shoes', 't-shirt', 'dress', 'jeans', 'blouse', 'skirt', 'skirt', 'shorts', 'jeans', 'dress', 't-shirt', 'dress', 'blouse', 't-shirt', 'dress', 'dress', 'dress', 'jeans', 'dress', 'blouse']\n",
    "\n",
    "closing_inventory = ['shoes', 'skirt', 'jeans', 'blouse', 'dress', 'skirt', 'shorts', 'jeans', 'dress', 'dress', 'jeans', 'dress', 'blouse']\n",
    "\n",
    "def find_amount_sold(opening, closing, item):\n",
    "    opening_count = Counter(opening)\n",
    "    closing_count = Counter(closing)\n",
    "    opening_count.subtract(closing_count)\n",
    "    return opening_count[item]\n",
    "\n",
    "tshirts_sold = find_amount_sold(opening_inventory, closing_inventory, 't-shirt')  \n",
    "print(tshirts_sold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af595a83-f9d7-41b8-8fa4-86c162a60949",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Container Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ccd7d-b6b3-44c2-99ad-85d650bca14c",
   "metadata": {},
   "source": [
    "#### UserDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9e766b6-439c-4c22-8403-242752d15cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order_4829': {'type': 't-shirt', 'size': 'large', 'price': 9.99, 'order_status': 'processing'}, 'order_7378': {'type': 'jacket', 'size': 'large', 'price': 24.99, 'order_status': 'processing'}}\n"
     ]
    }
   ],
   "source": [
    "from collections import UserDict\n",
    "data = {'order_4829': {'type': 't-shirt', 'size': 'large', 'price': 9.99, 'order_status': 'processing'},\n",
    "        'order_6184': {'type': 'pants', 'size': 'medium', 'price': 14.99, 'order_status': 'complete'},\n",
    "        'order_2905': {'type': 'shoes', 'size': 12, 'price': 22.50, 'order_status': 'complete'},\n",
    "        'order_7378': {'type': 'jacket', 'size': 'large', 'price': 24.99, 'order_status': 'processing'}}\n",
    "\n",
    "class OrderProcessingDict(UserDict):\n",
    "    def clean_orders(self):\n",
    "        deleted_items = []\n",
    "    \n",
    "        for i in self.keys():\n",
    "            if self.data[i]['order_status'] == 'complete':\n",
    "                deleted_items.append(i)\n",
    "\n",
    "        for j in deleted_items:\n",
    "            del self.data[j]\n",
    "\n",
    "process_dict = OrderProcessingDict(data)\n",
    "process_dict.clean_orders()\n",
    "print(process_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df73057-d1be-4f83-bbca-b661184da1df",
   "metadata": {},
   "source": [
    "#### UserList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "189e3614-725e-489a-a0ad-71ff2ea7b1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "from collections import UserList\n",
    "data = [4, 6, 8, 9, 2, 5, 7, 3, 1, 0]\n",
    "\n",
    "class ListSorter(UserList):\n",
    "\n",
    "    def append(self, item):\n",
    "        self.data.append(item)\n",
    "        self.data.sort()\n",
    "\n",
    "sorted_list = ListSorter(data)\n",
    "sorted_list.append(2)\n",
    "print(sorted_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6724f-ede6-45c0-a2cc-6b19550194e2",
   "metadata": {},
   "source": [
    "#### UserString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07cb6d0f-9bbd-4f97-b690-457bd852062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python powered products\n"
     ]
    }
   ],
   "source": [
    "from collections import UserString\n",
    "str_name = 'python powered patterned products'\n",
    "str_word = 'patterned '\n",
    "\n",
    "class SubtractString(UserString):\n",
    "    def __sub__(self, other):\n",
    "        if other in self.data:\n",
    "            self.data = self.data.replace(other, '')\n",
    "\n",
    "subtract_string = SubtractString(str_name)\n",
    "subtract_string - str_word\n",
    "print(subtract_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
